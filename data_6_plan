
1）李理的博客
2）SDT（sequence-discriminative training）序列区分性训练
	https://blog.csdn.net/xmdxcsj/article/details/52760111
	DNN训练使用的准则是CE准则，更加注重每一帧的分类和优化，最小化帧的错误率，但是实际上语音识别是一个序列分类的问题，更加关心序列的准确性，所以引入SDT，训练准则更加符合实际情况，有利于提升识别率，常用的准则包括：MMI/BMMI、MPE、MBR等


博客一：https://blog.csdn.net/u013569304/article/details/81320224
首先介绍：
    GMM-HMM：
    	1）每一个词的发音都对应一个HMM模型，HMM模型中的状态集是S，是通过先验知识认为设定的。（有待细究）
   	2）HMM的每一个状态，都对应一个观测值，每一个状态对应的观测值的维度应该是相同的。
    	3）对每一个单词建立一个HMM模型，需要用该单词的训练样本（是提前标注好的），然后结合Baum-Welch算法和EM算法来训练出GMM-HMM的所有参数，这些参数包括：初始状态的概率向量、状态之间的转移矩阵、每个状态对应的观察矩阵（这里对应的是GMM、即每个状态对应的k个高斯的权值、每个高斯的均值和方差矩阵）
然后介绍：    
    深度神经网络序列鉴别性训练：
	传统的DNN进行多分类的时候通常采用的是“交叉熵损失函数”，它能够独立处理每一帧的语音向量，但是语音识别的本质是序列分类问题，DNN的输入也是一长段的帧，所以我们需要引入一些更加契合这种问题的序列区分鉴别性训练方法，比如常用的最大互信息（MMI），增强型最大互信息（BMMI），最小音素错误（MPE），和最小贝叶斯风险训练准则（MBR）。
	这里简单介绍一下这几种方法的基本思想，语音识别中使用的最大互信息（MMI）准则旨在最大化单词序列分布和观察序列分布的互信息。增强型MMI是MMI准则的一个变种，它增强了错误较多的路径的似然度。最小音素错误和状态级最小贝叶斯风险都旨在最小化不同颗粒度标注下的期望错误。比如，MPE准则旨在最小化期望音素错误，而状态级贝叶斯风险（sMBR）旨在最小化状态错误的统计期望。
	词图（lattice），词图本质上是一个有向无环（directed acyclic graph）图。每个词网格包含一个开始结点以及一个结束结点，即在每个词网格中，仅存在一个入度（in-degree）为0的节点和一个出度（out-degree）为0的节点。我们也一般采用词图来保存识别的候选序列。
推荐博客：https://blog.csdn.net/xmdxcsj/article/details/52760111（全是公式）
*******************************************************
*总结：主要了解了序列区分性训练的意思，lattice的含义。*
*******************************************************
博客二：https://www.jianshu.com/p/a0e01b682e8a
浅谈语音识别基础：
	一：声学模型处理的问题主要在于“特征向量序列的可变长和音频信号的丰富变化性”，因为语音长度是不确定的，所以特征序列的长度也是不确定的，我们一般通过动态时间规整方法和隐马尔可夫模型来处理。
	二：透彻理解高斯分布https://baijiahao.baidu.com/s?id=1621087027738177317&wfr=spider&for=pc（中间了解）
	**********************************************************************************************************************************
	*高斯分布重要量的性质：（1）密度函数关于平均值对称；（2）平均值是它的众数（statistical mode）以及中位数（median）。68-95-99.7法则*
	**********************************************************************************************************************************
	还需要仔细研究一下。
	三：协方差矩阵
	？？？？？？？？？
	协方差矩阵用于描述不同维度变量之间的相关关系。如果我们采用了对角阵，看似是假设了数据向量的各个维度不相关，但是实际上，因为混混合高斯模型具有多个高斯成分，多个模态，所以虽然每个成分都使用了对角协方差矩阵，但总体上至少可以有效地描述由一个使用全协方差矩阵的单高斯模型所描述的向量维度相关性。（不太懂）
	四：GMM的缺点：？？？？？？
	GMM尽管有着众多优势，但也有一个严重的不足，就是GMM不能有效地对呈非线性或近似非线性的数据进行建模。比如描述一个球面，如果选择合适的模型，只需要很少的参数，而GMM却需要非常多对角协方差高斯分布或相当多的全协方差高斯分布。
	
	





